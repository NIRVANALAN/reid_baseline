This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0
[Resize(size=(256, 128), interpolation=PIL.Image.BICUBIC), Pad(padding=10, fill=0, padding_mode=constant), RandomCrop(size=(256, 128), padding=0), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), <random_erasing.RandomErasing object at 0x7f2b7975b550>]
4.76837158203125e-06
ft_net(
  (branch2_layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
  )
  (model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (class_0): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_1): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_2): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_3): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_4): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_5): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_6): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_7): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_8): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_9): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_10): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_11): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_12): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_13): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_14): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_15): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_16): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_17): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_18): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_19): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_20): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_21): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_22): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_23): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_24): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_25): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_26): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_27): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_28): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_29): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_30): ClassBlock(
    (dropout): Dropout(p=0.5)
    (add_block): Sequential(
      (0): Linear(in_features=2048, out_features=256, bias=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (classifier): Sequential(
      (0): Linear(in_features=256, out_features=751, bias=True)
    )
  )
)
Epoch 0/59
----------
train Loss: 3.7280 Acc: 0.3541
val Loss: 8.7432 Acc: 0.0018
Training complete in 5m 52s

Epoch 1/59
----------
train Loss: 0.7349 Acc: 0.8687
val Loss: 10.1109 Acc: 0.0024
Training complete in 11m 40s

Epoch 2/59
----------
train Loss: 0.1884 Acc: 0.9728
val Loss: 10.8187 Acc: 0.0018
Training complete in 17m 29s

Epoch 3/59
----------
train Loss: 0.0587 Acc: 0.9930
val Loss: 10.9595 Acc: 0.0021
Training complete in 23m 18s

Epoch 4/59
----------
train Loss: 0.0259 Acc: 0.9976
val Loss: 11.3200 Acc: 0.0030
Training complete in 29m 7s

Epoch 5/59
----------
train Loss: 0.0164 Acc: 0.9979
val Loss: 11.3793 Acc: 0.0030
Training complete in 34m 56s

Epoch 6/59
----------
train Loss: 0.0130 Acc: 0.9986
val Loss: 11.3760 Acc: 0.0027
Training complete in 40m 46s

Epoch 7/59
----------
train Loss: 0.0079 Acc: 0.9993
val Loss: 11.3396 Acc: 0.0027
Training complete in 46m 35s

Epoch 8/59
----------
train Loss: 0.0089 Acc: 0.9988
val Loss: 11.2898 Acc: 0.0030
Training complete in 52m 24s

Epoch 9/59
----------
train Loss: 0.0060 Acc: 0.9994
val Loss: 11.3354 Acc: 0.0033
Training complete in 58m 17s

Epoch 10/59
----------
train Loss: 0.0053 Acc: 0.9994
val Loss: 11.2574 Acc: 0.0033
Training complete in 64m 6s

Epoch 11/59
----------
train Loss: 0.0049 Acc: 0.9994
val Loss: 11.2458 Acc: 0.0024
Training complete in 69m 57s

Epoch 12/59
----------
train Loss: 0.0046 Acc: 0.9994
val Loss: 11.2178 Acc: 0.0024
Training complete in 75m 48s

Epoch 13/59
----------
train Loss: 0.0044 Acc: 0.9994
val Loss: 11.2008 Acc: 0.0030
Training complete in 81m 37s

Epoch 14/59
----------
train Loss: 0.0042 Acc: 0.9994
val Loss: 11.1665 Acc: 0.0027
Training complete in 87m 27s

Epoch 15/59
----------
train Loss: 0.0041 Acc: 0.9994
val Loss: 11.1232 Acc: 0.0030
Training complete in 93m 18s

Epoch 16/59
----------
train Loss: 0.0039 Acc: 0.9994
val Loss: 11.0873 Acc: 0.0027
Training complete in 99m 8s

Epoch 17/59
----------
train Loss: 0.0039 Acc: 0.9994
val Loss: 11.0590 Acc: 0.0030
Training complete in 104m 58s

Epoch 18/59
----------
train Loss: 0.0038 Acc: 0.9994
val Loss: 11.0549 Acc: 0.0024
Training complete in 110m 48s

Epoch 19/59
----------
train Loss: 0.0037 Acc: 0.9994
val Loss: 11.0593 Acc: 0.0030
Training complete in 116m 41s

Epoch 20/59
----------
train Loss: 0.0036 Acc: 0.9994
val Loss: 10.9670 Acc: 0.0030
Training complete in 122m 32s

Epoch 21/59
----------
train Loss: 0.0035 Acc: 0.9994
val Loss: 10.9021 Acc: 0.0027
Training complete in 128m 22s

Epoch 22/59
----------
train Loss: 0.0034 Acc: 0.9994
val Loss: 10.9412 Acc: 0.0030
Training complete in 134m 11s

Epoch 23/59
----------
train Loss: 0.0033 Acc: 0.9994
val Loss: 10.9330 Acc: 0.0027
Training complete in 140m 1s

Epoch 24/59
----------
train Loss: 0.0033 Acc: 0.9994
val Loss: 10.8853 Acc: 0.0030
Training complete in 145m 52s

Epoch 25/59
----------
train Loss: 0.0033 Acc: 0.9994
val Loss: 10.8670 Acc: 0.0027
Training complete in 151m 42s

Epoch 26/59
----------
train Loss: 0.0032 Acc: 0.9994
val Loss: 10.8230 Acc: 0.0024
Training complete in 157m 32s

Epoch 27/59
----------
train Loss: 0.0032 Acc: 0.9994
val Loss: 10.7636 Acc: 0.0027
Training complete in 163m 22s

Epoch 28/59
----------
train Loss: 0.0032 Acc: 0.9994
val Loss: 10.7275 Acc: 0.0027
Training complete in 169m 13s

Epoch 29/59
----------
