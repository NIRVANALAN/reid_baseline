This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0
[Resize(size=(256, 128), interpolation=PIL.Image.BICUBIC), Pad(padding=10, fill=0, padding_mode=constant), RandomCrop(size=(256, 128), padding=0), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]
1.9073486328125e-06
ft_net(
  (model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (class_0): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_1): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_2): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_3): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_4): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_5): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_6): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_7): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_8): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_9): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_10): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_11): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_12): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_13): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_14): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_15): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_16): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_17): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_18): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_19): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_20): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_21): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_22): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_23): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_24): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_25): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_26): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_27): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_28): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_29): Sequential(
    (0): weighted_avg_pooling(
      (part_detector_block): Sequential(
        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
    )
    (1): ClassBlock(
      (dropout): Dropout(p=0.5)
      (add_block): Sequential(
        (0): Linear(in_features=2048, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (classifier): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
  (class_30): ClassBlock(
    (dropout): Dropout(p=0.5)
    (add_block): Sequential(
      (0): Linear(in_features=2048, out_features=256, bias=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (classifier): Sequential(
      (0): Linear(in_features=256, out_features=751, bias=True)
    )
  )
)
Epoch 0/59
----------
train Loss: 4.1217 Acc: 0.2086
val Loss: 10.7218 Acc: 0.0015
Training complete in 2m 59s

Epoch 1/59
----------
train Loss: 1.8690 Acc: 0.5339
val Loss: 12.3410 Acc: 0.0021
Training complete in 5m 53s

Epoch 2/59
----------
train Loss: 1.1111 Acc: 0.6965
val Loss: 14.3198 Acc: 0.0009
Training complete in 8m 49s

Epoch 3/59
----------
train Loss: 0.8132 Acc: 0.7720
val Loss: 15.2488 Acc: 0.0012
Training complete in 11m 45s

Epoch 4/59
----------
train Loss: 0.6242 Acc: 0.8238
val Loss: 16.1570 Acc: 0.0015
Training complete in 14m 41s

Epoch 5/59
----------
train Loss: 0.4965 Acc: 0.8605
val Loss: 16.8421 Acc: 0.0018
Training complete in 17m 38s

Epoch 6/59
----------
train Loss: 0.3875 Acc: 0.8870
val Loss: 16.6871 Acc: 0.0006
Training complete in 20m 35s

Epoch 7/59
----------
train Loss: 0.3218 Acc: 0.9046
val Loss: 17.5095 Acc: 0.0021
Training complete in 23m 32s

Epoch 8/59
----------
train Loss: 0.2587 Acc: 0.9247
val Loss: 17.5171 Acc: 0.0000
Training complete in 26m 29s

Epoch 9/59
----------
train Loss: 0.2033 Acc: 0.9373
val Loss: 18.0174 Acc: 0.0021
Training complete in 29m 29s

Epoch 10/59
----------
train Loss: 0.1966 Acc: 0.9412
val Loss: 18.4779 Acc: 0.0012
Training complete in 32m 25s

Epoch 11/59
----------
train Loss: 0.1650 Acc: 0.9491
val Loss: 18.3520 Acc: 0.0009
Training complete in 35m 22s

Epoch 12/59
----------
train Loss: 0.1350 Acc: 0.9605
val Loss: 18.6061 Acc: 0.0021
Training complete in 38m 18s

Epoch 13/59
----------
train Loss: 0.1272 Acc: 0.9609
val Loss: 18.7837 Acc: 0.0009
Training complete in 41m 15s

Epoch 14/59
----------
train Loss: 0.1109 Acc: 0.9681
val Loss: 18.9089 Acc: 0.0015
Training complete in 44m 11s

Epoch 15/59
----------
train Loss: 0.0908 Acc: 0.9719
val Loss: 18.5658 Acc: 0.0018
Training complete in 47m 8s

Epoch 16/59
----------
train Loss: 0.0937 Acc: 0.9722
val Loss: 18.7334 Acc: 0.0015
Training complete in 50m 4s

Epoch 17/59
----------
train Loss: 0.0826 Acc: 0.9764
val Loss: 18.6553 Acc: 0.0024
Training complete in 53m 1s

Epoch 18/59
----------
train Loss: 0.0764 Acc: 0.9774
val Loss: 18.4108 Acc: 0.0015
Training complete in 55m 58s

Epoch 19/59
----------
train Loss: 0.0656 Acc: 0.9808
val Loss: 19.0184 Acc: 0.0003
Training complete in 59m 34s

Epoch 20/59
----------
train Loss: 0.0466 Acc: 0.9865
val Loss: 18.8195 Acc: 0.0012
Training complete in 63m 43s

Epoch 21/59
----------
train Loss: 0.0448 Acc: 0.9863
val Loss: 18.7622 Acc: 0.0015
Training complete in 67m 18s

Epoch 22/59
----------
train Loss: 0.0478 Acc: 0.9865
val Loss: 18.9942 Acc: 0.0015
Training complete in 70m 15s

Epoch 23/59
----------
train Loss: 0.0432 Acc: 0.9879
val Loss: 18.5540 Acc: 0.0006
Training complete in 73m 13s

Epoch 24/59
----------
train Loss: 0.0342 Acc: 0.9912
val Loss: 18.4891 Acc: 0.0009
Training complete in 76m 10s

Epoch 25/59
----------
train Loss: 0.0422 Acc: 0.9882
val Loss: 18.4786 Acc: 0.0009
Training complete in 79m 6s

Epoch 26/59
----------
train Loss: 0.0296 Acc: 0.9926
val Loss: 18.4476 Acc: 0.0012
Training complete in 82m 3s

Epoch 27/59
----------
train Loss: 0.0238 Acc: 0.9938
val Loss: 18.0953 Acc: 0.0015
Training complete in 84m 59s

Epoch 28/59
----------
train Loss: 0.0238 Acc: 0.9937
val Loss: 18.2144 Acc: 0.0012
Training complete in 87m 58s

Epoch 29/59
----------
train Loss: 0.0216 Acc: 0.9946
val Loss: 18.1743 Acc: 0.0009
Training complete in 90m 60s

Epoch 30/59
----------
train Loss: 0.0212 Acc: 0.9952
val Loss: 18.0609 Acc: 0.0021
Training complete in 93m 58s

Epoch 31/59
----------
train Loss: 0.0159 Acc: 0.9970
val Loss: 17.7039 Acc: 0.0003
Training complete in 96m 54s

Epoch 32/59
----------
train Loss: 0.0142 Acc: 0.9971
val Loss: 17.6628 Acc: 0.0015
Training complete in 99m 51s

Epoch 33/59
----------
train Loss: 0.0126 Acc: 0.9969
val Loss: 17.3929 Acc: 0.0009
Training complete in 102m 47s

Epoch 34/59
----------
train Loss: 0.0098 Acc: 0.9978
val Loss: 17.0663 Acc: 0.0024
Training complete in 105m 43s

Epoch 35/59
----------
train Loss: 0.0096 Acc: 0.9981
val Loss: 17.1167 Acc: 0.0015
Training complete in 108m 41s

Epoch 36/59
----------
train Loss: 0.0070 Acc: 0.9987
val Loss: 16.9487 Acc: 0.0018
Training complete in 111m 37s

Epoch 37/59
----------
train Loss: 0.0063 Acc: 0.9985
val Loss: 16.9415 Acc: 0.0018
Training complete in 114m 34s

Epoch 38/59
----------
train Loss: 0.0063 Acc: 0.9987
val Loss: 16.7677 Acc: 0.0012
Training complete in 117m 30s

Epoch 39/59
----------
train Loss: 0.0078 Acc: 0.9981
val Loss: 16.5238 Acc: 0.0012
Training complete in 120m 29s

Epoch 40/59
----------
train Loss: 0.0055 Acc: 0.9991
val Loss: 16.6415 Acc: 0.0009
Training complete in 123m 25s

Epoch 41/59
----------
train Loss: 0.0047 Acc: 0.9991
val Loss: 16.5643 Acc: 0.0018
Training complete in 126m 22s

Epoch 42/59
----------
train Loss: 0.0044 Acc: 0.9992
val Loss: 16.5876 Acc: 0.0015
Training complete in 129m 18s

Epoch 43/59
----------
train Loss: 0.0042 Acc: 0.9992
val Loss: 16.3692 Acc: 0.0009
Training complete in 132m 14s

Epoch 44/59
----------
train Loss: 0.0039 Acc: 0.9992
val Loss: 16.4293 Acc: 0.0012
Training complete in 135m 10s

Epoch 45/59
----------
train Loss: 0.0036 Acc: 0.9993
val Loss: 16.5260 Acc: 0.0012
Training complete in 138m 7s

Epoch 46/59
----------
train Loss: 0.0037 Acc: 0.9992
val Loss: 16.4051 Acc: 0.0012
Training complete in 141m 3s

Epoch 47/59
----------
train Loss: 0.0036 Acc: 0.9992
val Loss: 16.3815 Acc: 0.0012
Training complete in 143m 60s

Epoch 48/59
----------
train Loss: 0.0033 Acc: 0.9993
val Loss: 16.3405 Acc: 0.0015
Training complete in 146m 56s

Epoch 49/59
----------
train Loss: 0.0031 Acc: 0.9994
val Loss: 16.2976 Acc: 0.0015
Training complete in 149m 54s

Epoch 50/59
----------
train Loss: 0.0032 Acc: 0.9992
val Loss: 16.3389 Acc: 0.0009
Training complete in 152m 50s

Epoch 51/59
----------
train Loss: 0.0032 Acc: 0.9992
val Loss: 16.3794 Acc: 0.0015
Training complete in 155m 47s

Epoch 52/59
----------
train Loss: 0.0032 Acc: 0.9993
val Loss: 16.3031 Acc: 0.0012
Training complete in 158m 43s

Epoch 53/59
----------
train Loss: 0.0032 Acc: 0.9993
val Loss: 16.0834 Acc: 0.0012
Training complete in 161m 39s

Epoch 54/59
----------
train Loss: 0.0032 Acc: 0.9994
val Loss: 16.1111 Acc: 0.0018
Training complete in 164m 35s

Epoch 55/59
----------
train Loss: 0.0033 Acc: 0.9994
val Loss: 16.1969 Acc: 0.0012
Training complete in 167m 31s

Epoch 56/59
----------
train Loss: 0.0031 Acc: 0.9992
val Loss: 16.1906 Acc: 0.0012
Training complete in 170m 27s

Epoch 57/59
----------
train Loss: 0.0033 Acc: 0.9993
val Loss: 16.2276 Acc: 0.0018
Training complete in 173m 23s

Epoch 58/59
----------
train Loss: 0.0031 Acc: 0.9994
val Loss: 16.1678 Acc: 0.0021
Training complete in 176m 20s

Epoch 59/59
----------
train Loss: 0.0030 Acc: 0.9993
val Loss: 16.3133 Acc: 0.0009
Training complete in 179m 20s

Training complete in 179m 20s
